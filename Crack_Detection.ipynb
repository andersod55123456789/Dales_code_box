{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT01GdWcIVR0tsToUPbjUS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andersod55123456789/Dales_code_box/blob/main/Crack_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvoJcZYzsVdS"
      },
      "outputs": [],
      "source": [
        "# Part Classification Model: Bright Crack Lines vs Dark Lap Lines\n",
        "# Designed for Google Colab\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files, drive\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Mount Google Drive (optional - for saving models)\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: DATA UPLOAD AND PREPARATION\n",
        "# =============================================================================\n",
        "\n",
        "def upload_and_extract_data():\n",
        "    \"\"\"Upload and extract your image data\"\"\"\n",
        "    print(\"Please upload your image folder as a ZIP file...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Extract the uploaded zip file\n",
        "    for filename in uploaded.keys():\n",
        "        print(f'Extracting {filename}...')\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/images')\n",
        "\n",
        "    # List the contents\n",
        "    image_dir = '/content/images'\n",
        "    if os.path.exists(image_dir):\n",
        "        print(f\"Images extracted to: {image_dir}\")\n",
        "        print(\"Contents:\", os.listdir(image_dir))\n",
        "        return image_dir\n",
        "    else:\n",
        "        print(\"Please check the extracted folder structure\")\n",
        "        return None\n",
        "\n",
        "def organize_data_for_training(image_dir, output_dir='/content/organized_data'):\n",
        "    \"\"\"\n",
        "    Organize images into training structure\n",
        "    You'll need to manually sort a few examples first, then we can use active learning\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(f'{output_dir}/crack_lines', exist_ok=True)\n",
        "    os.makedirs(f'{output_dir}/lap_lines', exist_ok=True)\n",
        "\n",
        "    # Get all image files\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
        "    image_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(image_dir):\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "                image_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"Found {len(image_files)} images\")\n",
        "\n",
        "    # Display first few images for manual classification\n",
        "    print(\"\\nDisplaying first 10 images for manual classification:\")\n",
        "    print(\"Please note which ones have CRACK LINES vs LAP LINES\")\n",
        "\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i, img_path in enumerate(image_files[:10]):\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            axes[i].imshow(img_rgb)\n",
        "            axes[i].set_title(f\"Image {i+1}: {os.path.basename(img_path)}\")\n",
        "            axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return image_files\n",
        "\n",
        "def manual_sort_initial_data(image_files, num_examples=50):\n",
        "    \"\"\"\n",
        "    Helper function for manual sorting of initial training data\n",
        "    \"\"\"\n",
        "    print(f\"\\nManual Classification Phase:\")\n",
        "    print(\"We'll show you {num_examples} images one by one.\")\n",
        "    print(\"Type 'c' for crack lines, 'l' for lap lines, 's' to skip\")\n",
        "\n",
        "    crack_examples = []\n",
        "    lap_examples = []\n",
        "\n",
        "    for i, img_path in enumerate(image_files[:num_examples]):\n",
        "        # Display image\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(img_rgb)\n",
        "        plt.title(f\"Image {i+1}/{num_examples}: {os.path.basename(img_path)}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # Get user input\n",
        "        while True:\n",
        "            label = input(\"Crack (c), Lap (l), or Skip (s)? \").lower().strip()\n",
        "            if label in ['c', 'l', 's']:\n",
        "                break\n",
        "            print(\"Please enter 'c', 'l', or 's'\")\n",
        "\n",
        "        if label == 'c':\n",
        "            crack_examples.append(img_path)\n",
        "            # Copy to crack folder\n",
        "            shutil.copy2(img_path, '/content/organized_data/crack_lines/')\n",
        "        elif label == 'l':\n",
        "            lap_examples.append(img_path)\n",
        "            # Copy to lap folder\n",
        "            shutil.copy2(img_path, '/content/organized_data/lap_lines/')\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "    print(f\"\\nManual classification complete!\")\n",
        "    print(f\"Crack examples: {len(crack_examples)}\")\n",
        "    print(f\"Lap examples: {len(lap_examples)}\")\n",
        "\n",
        "    return crack_examples, lap_examples\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: FEATURE EXTRACTION AND ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "def extract_line_features(image_path):\n",
        "    \"\"\"Extract features that distinguish bright cracks from dark laps\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    features = {}\n",
        "\n",
        "    # 1. Line detection using Hough Transform\n",
        "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=80)\n",
        "    features['num_lines'] = len(lines) if lines is not None else 0\n",
        "\n",
        "    # 2. Brightness statistics\n",
        "    features['mean_brightness'] = np.mean(gray)\n",
        "    features['std_brightness'] = np.std(gray)\n",
        "    features['max_brightness'] = np.max(gray)\n",
        "    features['min_brightness'] = np.min(gray)\n",
        "\n",
        "    # 3. Edge intensity\n",
        "    features['edge_intensity'] = np.mean(edges)\n",
        "    features['edge_count'] = np.sum(edges > 0)\n",
        "\n",
        "    # 4. Contrast measures\n",
        "    features['contrast'] = features['max_brightness'] - features['min_brightness']\n",
        "    features['rms_contrast'] = np.sqrt(np.mean((gray - features['mean_brightness'])**2))\n",
        "\n",
        "    # 5. Texture analysis using Local Binary Patterns\n",
        "    from skimage.feature import local_binary_pattern\n",
        "    lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
        "    features['lbp_uniformity'] = len(np.unique(lbp))\n",
        "\n",
        "    # 6. Gradient analysis\n",
        "    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
        "    features['gradient_mean'] = np.mean(gradient_magnitude)\n",
        "    features['gradient_std'] = np.std(gradient_magnitude)\n",
        "\n",
        "    return features\n",
        "\n",
        "def analyze_feature_differences(crack_examples, lap_examples):\n",
        "    \"\"\"Analyze the feature differences between crack and lap examples\"\"\"\n",
        "    crack_features = []\n",
        "    lap_features = []\n",
        "\n",
        "    print(\"Extracting features from crack examples...\")\n",
        "    for img_path in crack_examples:\n",
        "        features = extract_line_features(img_path)\n",
        "        if features:\n",
        "            features['label'] = 'crack'\n",
        "            crack_features.append(features)\n",
        "\n",
        "    print(\"Extracting features from lap examples...\")\n",
        "    for img_path in lap_examples:\n",
        "        features = extract_line_features(img_path)\n",
        "        if features:\n",
        "            features['label'] = 'lap'\n",
        "            lap_features.append(features)\n",
        "\n",
        "    # Create DataFrame for analysis\n",
        "    df = pd.DataFrame(crack_features + lap_features)\n",
        "\n",
        "    # Statistical analysis\n",
        "    print(\"\\nFeature Analysis:\")\n",
        "    for column in df.columns:\n",
        "        if column != 'label':\n",
        "            crack_mean = df[df['label'] == 'crack'][column].mean()\n",
        "            lap_mean = df[df['label'] == 'lap'][column].mean()\n",
        "            print(f\"{column}:\")\n",
        "            print(f\"  Crack mean: {crack_mean:.3f}\")\n",
        "            print(f\"  Lap mean: {lap_mean:.3f}\")\n",
        "            print(f\"  Difference: {abs(crack_mean - lap_mean):.3f}\")\n",
        "            print()\n",
        "\n",
        "    # Visualization\n",
        "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i, column in enumerate(numeric_columns[:9]):\n",
        "        df.boxplot(column=column, by='label', ax=axes[i])\n",
        "        axes[i].set_title(f'{column}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return df\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: CNN MODEL BUILDING\n",
        "# =============================================================================\n",
        "\n",
        "def create_cnn_model(input_shape=(224, 224, 3)):\n",
        "    \"\"\"Create a CNN model optimized for line detection\"\"\"\n",
        "    model = models.Sequential([\n",
        "        # First convolutional block\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Second convolutional block\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Third convolutional block\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Fourth convolutional block\n",
        "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Global average pooling instead of flatten to reduce overfitting\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "\n",
        "        # Dense layers\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'precision', 'recall']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def prepare_data_generators(data_dir, img_size=(224, 224), batch_size=32):\n",
        "    \"\"\"Prepare data generators with augmentation\"\"\"\n",
        "\n",
        "    # Data augmentation for training\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        validation_split=0.2  # 20% for validation\n",
        "    )\n",
        "\n",
        "    # Only rescaling for validation\n",
        "    val_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    # Create generators\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        subset='training',\n",
        "        classes=['crack_lines', 'lap_lines']  # 0 = crack, 1 = lap\n",
        "    )\n",
        "\n",
        "    validation_generator = val_datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        subset='validation',\n",
        "        classes=['crack_lines', 'lap_lines']\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "def train_model(model, train_gen, val_gen, epochs=50):\n",
        "    \"\"\"Train the model with callbacks\"\"\"\n",
        "\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=5,\n",
        "            min_lr=1e-7\n",
        "        ),\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            'best_model.h5',\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=epochs,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training history\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    axes[0, 0].set_title('Model Accuracy')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "    # Loss\n",
        "    axes[0, 1].plot(history.history['loss'], label='Training Loss')\n",
        "    axes[0, 1].plot(history.history['val_loss'], label='Validation Loss')\n",
        "    axes[0, 1].set_title('Model Loss')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "\n",
        "    # Precision\n",
        "    axes[1, 0].plot(history.history['precision'], label='Training Precision')\n",
        "    axes[1, 0].plot(history.history['val_precision'], label='Validation Precision')\n",
        "    axes[1, 0].set_title('Model Precision')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Precision')\n",
        "    axes[1, 0].legend()\n",
        "\n",
        "    # Recall\n",
        "    axes[1, 1].plot(history.history['recall'], label='Training Recall')\n",
        "    axes[1, 1].plot(history.history['val_recall'], label='Validation Recall')\n",
        "    axes[1, 1].set_title('Model Recall')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Recall')\n",
        "    axes[1, 1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: MODEL EVALUATION AND SORTING\n",
        "# =============================================================================\n",
        "\n",
        "def evaluate_model(model, val_gen):\n",
        "    \"\"\"Evaluate model performance\"\"\"\n",
        "    # Get predictions\n",
        "    val_gen.reset()\n",
        "    predictions = model.predict(val_gen)\n",
        "    y_pred = (predictions > 0.5).astype(int).flatten()\n",
        "    y_true = val_gen.classes\n",
        "\n",
        "    # Classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=['Crack Lines', 'Lap Lines']))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Crack Lines', 'Lap Lines'],\n",
        "                yticklabels=['Crack Lines', 'Lap Lines'])\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy_score(y_true, y_pred)\n",
        "\n",
        "def sort_images(model, image_dir, output_dir='/content/sorted_images'):\n",
        "    \"\"\"Sort all images using the trained model\"\"\"\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(f'{output_dir}/crack_lines', exist_ok=True)\n",
        "    os.makedirs(f'{output_dir}/lap_lines', exist_ok=True)\n",
        "    os.makedirs(f'{output_dir}/uncertain', exist_ok=True)\n",
        "\n",
        "    # Get all image files\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
        "    image_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(image_dir):\n",
        "        for file in files:\n",
        "            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
        "                image_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"Sorting {len(image_files)} images...\")\n",
        "\n",
        "    crack_count = 0\n",
        "    lap_count = 0\n",
        "    uncertain_count = 0\n",
        "\n",
        "    for img_path in image_files:\n",
        "        try:\n",
        "            # Load and preprocess image\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img_resized = cv2.resize(img_rgb, (224, 224))\n",
        "            img_normalized = img_resized / 255.0\n",
        "            img_batch = np.expand_dims(img_normalized, axis=0)\n",
        "\n",
        "            # Predict\n",
        "            prediction = model.predict(img_batch, verbose=0)[0][0]\n",
        "\n",
        "            # Sort based on prediction confidence\n",
        "            filename = os.path.basename(img_path)\n",
        "\n",
        "            if prediction < 0.3:  # Strong crack prediction\n",
        "                shutil.copy2(img_path, f'{output_dir}/crack_lines/{filename}')\n",
        "                crack_count += 1\n",
        "            elif prediction > 0.7:  # Strong lap prediction\n",
        "                shutil.copy2(img_path, f'{output_dir}/lap_lines/{filename}')\n",
        "                lap_count += 1\n",
        "            else:  # Uncertain predictions\n",
        "                shutil.copy2(img_path, f'{output_dir}/uncertain/{filename}')\n",
        "                uncertain_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "    print(f\"\\nSorting complete!\")\n",
        "    print(f\"Crack lines: {crack_count}\")\n",
        "    print(f\"Lap lines: {lap_count}\")\n",
        "    print(f\"Uncertain: {uncertain_count}\")\n",
        "\n",
        "    return crack_count, lap_count, uncertain_count\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN EXECUTION PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "def main_pipeline():\n",
        "    \"\"\"Main execution pipeline\"\"\"\n",
        "    print(\"=== PART CLASSIFICATION MODEL ===\")\n",
        "    print(\"This model will classify parts with bright crack lines vs dark lap lines\")\n",
        "\n",
        "    # Step 1: Upload and prepare data\n",
        "    print(\"\\n1. UPLOADING AND PREPARING DATA\")\n",
        "    print(\"Please zip your image folder and upload it when prompted.\")\n",
        "\n",
        "    # Uncomment these lines when ready to run:\n",
        "    # image_dir = upload_and_extract_data()\n",
        "    # if not image_dir:\n",
        "    #     return\n",
        "\n",
        "    # image_files = organize_data_for_training(image_dir)\n",
        "    # crack_examples, lap_examples = manual_sort_initial_data(image_files)\n",
        "\n",
        "    # Step 2: Feature analysis (optional but recommended)\n",
        "    print(\"\\n2. FEATURE ANALYSIS\")\n",
        "    # df = analyze_feature_differences(crack_examples, lap_examples)\n",
        "\n",
        "    # Step 3: Train CNN model\n",
        "    print(\"\\n3. TRAINING CNN MODEL\")\n",
        "    model = create_cnn_model()\n",
        "    print(\"Model architecture:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Prepare data generators\n",
        "    # train_gen, val_gen = prepare_data_generators('/content/organized_data')\n",
        "\n",
        "    # Train model\n",
        "    # history = train_model(model, train_gen, val_gen, epochs=50)\n",
        "    # plot_training_history(history)\n",
        "\n",
        "    # Step 4: Evaluate model\n",
        "    print(\"\\n4. MODEL EVALUATION\")\n",
        "    # accuracy = evaluate_model(model, val_gen)\n",
        "    # print(f\"Final validation accuracy: {accuracy:.3f}\")\n",
        "\n",
        "    # Step 5: Sort all images\n",
        "    print(\"\\n5. SORTING ALL IMAGES\")\n",
        "    # sort_images(model, image_dir)\n",
        "\n",
        "    print(\"\\n=== PIPELINE COMPLETE ===\")\n",
        "    print(\"Check the /content/sorted_images folder for results!\")\n",
        "\n",
        "# Instructions for running\n",
        "print(\"\"\"\n",
        "INSTRUCTIONS FOR USE:\n",
        "\n",
        "1. Upload this notebook to Google Colab\n",
        "2. Run the setup cells to install dependencies\n",
        "3. Zip your image folder (C:\\\\Users\\\\Tenne\\\\Desktop\\\\OneDrive_1_8-8-2025)\n",
        "4. Run main_pipeline() and follow the prompts\n",
        "5. Manually classify ~50 initial examples when prompted\n",
        "6. The model will train and then sort all your images\n",
        "\n",
        "The model will create three folders:\n",
        "- crack_lines: Images with bright crack lines (confident predictions)\n",
        "- lap_lines: Images with dark lap lines (confident predictions)\n",
        "- uncertain: Images the model is unsure about (manual review recommended)\n",
        "\n",
        "Uncomment the lines in main_pipeline() when ready to run!\n",
        "\"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Uncomment the next line when ready to run the full pipeline\n",
        "    # main_pipeline()\n",
        "    pass"
      ]
    }
  ]
}